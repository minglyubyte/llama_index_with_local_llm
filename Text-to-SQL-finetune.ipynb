{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a57838-3239-4291-8f6a-5bd92cd76bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leo/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging\n",
    ")\n",
    "from peft import LoraConfig, PeftModel, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d365493-1324-4aff-8ddf-86deabdda6ee",
   "metadata": {},
   "source": [
    "# Preparing Data for fine-tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf9fe1c-e241-42a2-a089-e06c77c960c3",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "Using huggingface dataset \"Text-to-sql-v1\", we have the instruction, input and response. Next step is to create a prompt dataset to fine-tune llama2 open source model.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4040f1f0-b767-4361-9fe0-6599c4f01b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'response', 'source', 'text'],\n",
       "        num_rows: 262208\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Clinton/Text-to-sql-v1\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "891423a1-6908-44d4-848e-db8c01a9b21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262208"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_total = dataset['train']\n",
    "len(dataset_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f44ccb6-c43f-452c-8387-8e37b91ed808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Name the home team for carlton away team',\n",
       " 'input': 'CREATE TABLE table_name_77 (\\n    home_team VARCHAR,\\n    away_team VARCHAR\\n)',\n",
       " 'response': 'SELECT home_team FROM table_name_77 WHERE away_team = \"carlton\"',\n",
       " 'source': 'sql_create_context',\n",
       " 'text': 'Below are sql tables schemas paired with instruction that describes a task. Using valid SQLite, write a response that appropriately completes the request for the provided tables. ### Instruction: Name the home team for carlton away team ### Input: CREATE TABLE table_name_77 (\\n    home_team VARCHAR,\\n    away_team VARCHAR\\n) ### Response: SELECT home_team FROM table_name_77 WHERE away_team = \"carlton\"'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_total[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee1b00b6-cced-4ec8-b7c4-51eab2de2671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Below are sql tables schemas paired with instruction that describes a task. Using valid SQLite, write a response that appropriately completes the request for the provided tables. ',\n",
       " ' Instruction: Name the home team for carlton away team ',\n",
       " ' Input: CREATE TABLE table_name_77 (\\n    home_team VARCHAR,\\n    away_team VARCHAR\\n) ',\n",
       " ' Response: SELECT home_team FROM table_name_77 WHERE away_team = \"carlton\"']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_l = dataset_total[0]['text'].split(\"###\")\n",
    "input_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2e0aa7-4174-4e2c-ab86-ed380bd7f3cb",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "Follow the llama2 prompt template to include system instruction, the input query and output response in the training data. Next step is to do train, validation and test data split. However, since there are over 250,000 data points, due to computational limit, we just randomly pick 20,000 data points for fine-tuning.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5e34e66-ccdf-4464-963b-1e6378da8809",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "system_prompt = \"\"\"Below are sql tables schemas paired with instruction that describes a task. \n",
    "                Using valid SQLite, write a response that appropriately completes the request \n",
    "                for the provided tables. \"\"\"\n",
    "for i in range(len(dataset_total)):\n",
    "    query = dataset_total[i]['instruction'] + dataset_total[i]['input']\n",
    "    prompt = \"[INST]<<SYS>>\\n{}<</SYS>>\\n\\n{}[/INST]{}</s>\".format(system_prompt, query, dataset_total[i]['response'])\n",
    "    df_list.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d262150-9f25-460e-8e04-b5f0f8d4c083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[INST]<<SYS>>\\nBelow are sql tables schemas paired with instruction that describes a task. \\n                Using valid SQLite, write a response that appropriately completes the request \\n                for the provided tables. <</SYS>>\\n\\nMy median and average answer score at given date. Reports median and average answer score. The MedianAnswerScore2 is more precise version of median.CREATE TABLE CloseReasonTypes (\\n    Id number,\\n    Name text,\\n    Description text\\n)\\n\\nCREATE TABLE ReviewTaskResultTypes (\\n    Id number,\\n    Name text,\\n    Description text\\n)\\n\\nCREATE TABLE PostFeedback (\\n    Id number,\\n    PostId number,\\n    IsAnonymous boolean,\\n    VoteTypeId number,\\n    CreationDate time\\n)\\n\\nCREATE TABLE ReviewTaskResults (\\n    Id number,\\n    ReviewTaskId number,\\n    ReviewTaskResultTypeId number,\\n    CreationDate time,\\n    RejectionReasonId number,\\n    Comment text\\n)\\n\\nCREATE TABLE FlagTypes (\\n    Id number,\\n    Name text,\\n    Description text\\n)\\n\\nCREATE TABLE PostTags (\\n    PostId number,\\n    TagId number\\n)\\n\\nCREATE TABLE PostHistoryTypes (\\n    Id number,\\n    Name text\\n)\\n\\nCREATE TABLE ReviewTaskStates (\\n    Id number,\\n    Name text,\\n    Description text\\n)\\n\\nCREATE TABLE PostNoticeTypes (\\n    Id number,\\n    ClassId number,\\n    Name text,\\n    Body text,\\n    IsHidden boolean,\\n    Predefined boolean,\\n    PostNoticeDurationId number\\n)\\n\\nCREATE TABLE PostHistory (\\n    Id number,\\n    PostHistoryTypeId number,\\n    PostId number,\\n    RevisionGUID other,\\n    CreationDate time,\\n    UserId number,\\n    UserDisplayName text,\\n    Comment text,\\n    Text text,\\n    ContentLicense text\\n)\\n\\nCREATE TABLE PendingFlags (\\n    Id number,\\n    FlagTypeId number,\\n    PostId number,\\n    CreationDate time,\\n    CloseReasonTypeId number,\\n    CloseAsOffTopicReasonTypeId number,\\n    DuplicateOfQuestionId number,\\n    BelongsOnBaseHostAddress text\\n)\\n\\nCREATE TABLE PostsWithDeleted (\\n    Id number,\\n    PostTypeId number,\\n    AcceptedAnswerId number,\\n    ParentId number,\\n    CreationDate time,\\n    DeletionDate time,\\n    Score number,\\n    ViewCount number,\\n    Body text,\\n    OwnerUserId number,\\n    OwnerDisplayName text,\\n    LastEditorUserId number,\\n    LastEditorDisplayName text,\\n    LastEditDate time,\\n    LastActivityDate time,\\n    Title text,\\n    Tags text,\\n    AnswerCount number,\\n    CommentCount number,\\n    FavoriteCount number,\\n    ClosedDate time,\\n    CommunityOwnedDate time,\\n    ContentLicense text\\n)\\n\\nCREATE TABLE PostTypes (\\n    Id number,\\n    Name text\\n)\\n\\nCREATE TABLE VoteTypes (\\n    Id number,\\n    Name text\\n)\\n\\nCREATE TABLE ReviewTasks (\\n    Id number,\\n    ReviewTaskTypeId number,\\n    CreationDate time,\\n    DeletionDate time,\\n    ReviewTaskStateId number,\\n    PostId number,\\n    SuggestedEditId number,\\n    CompletedByReviewTaskId number\\n)\\n\\nCREATE TABLE Posts (\\n    Id number,\\n    PostTypeId number,\\n    AcceptedAnswerId number,\\n    ParentId number,\\n    CreationDate time,\\n    DeletionDate time,\\n    Score number,\\n    ViewCount number,\\n    Body text,\\n    OwnerUserId number,\\n    OwnerDisplayName text,\\n    LastEditorUserId number,\\n    LastEditorDisplayName text,\\n    LastEditDate time,\\n    LastActivityDate time,\\n    Title text,\\n    Tags text,\\n    AnswerCount number,\\n    CommentCount number,\\n    FavoriteCount number,\\n    ClosedDate time,\\n    CommunityOwnedDate time,\\n    ContentLicense text\\n)\\n\\nCREATE TABLE Users (\\n    Id number,\\n    Reputation number,\\n    CreationDate time,\\n    DisplayName text,\\n    LastAccessDate time,\\n    WebsiteUrl text,\\n    Location text,\\n    AboutMe text,\\n    Views number,\\n    UpVotes number,\\n    DownVotes number,\\n    ProfileImageUrl text,\\n    EmailHash text,\\n    AccountId number\\n)\\n\\nCREATE TABLE Votes (\\n    Id number,\\n    PostId number,\\n    VoteTypeId number,\\n    UserId number,\\n    CreationDate time,\\n    BountyAmount number\\n)\\n\\nCREATE TABLE PostNotices (\\n    Id number,\\n    PostId number,\\n    PostNoticeTypeId number,\\n    CreationDate time,\\n    DeletionDate time,\\n    ExpiryDate time,\\n    Body text,\\n    OwnerUserId number,\\n    DeletionUserId number\\n)\\n\\nCREATE TABLE SuggestedEditVotes (\\n    Id number,\\n    SuggestedEditId number,\\n    UserId number,\\n    VoteTypeId number,\\n    CreationDate time,\\n    TargetUserId number,\\n    TargetRepChange number\\n)\\n\\nCREATE TABLE ReviewRejectionReasons (\\n    Id number,\\n    Name text,\\n    Description text,\\n    PostTypeId number\\n)\\n\\nCREATE TABLE Badges (\\n    Id number,\\n    UserId number,\\n    Name text,\\n    Date time,\\n    Class number,\\n    TagBased boolean\\n)\\n\\nCREATE TABLE Tags (\\n    Id number,\\n    TagName text,\\n    Count number,\\n    ExcerptPostId number,\\n    WikiPostId number\\n)\\n\\nCREATE TABLE CloseAsOffTopicReasonTypes (\\n    Id number,\\n    IsUniversal boolean,\\n    InputTitle text,\\n    MarkdownInputGuidance text,\\n    MarkdownPostOwnerGuidance text,\\n    MarkdownPrivilegedUserGuidance text,\\n    MarkdownConcensusDescription text,\\n    CreationDate time,\\n    CreationModeratorId number,\\n    ApprovalDate time,\\n    ApprovalModeratorId number,\\n    DeactivationDate time,\\n    DeactivationModeratorId number\\n)\\n\\nCREATE TABLE SuggestedEdits (\\n    Id number,\\n    PostId number,\\n    CreationDate time,\\n    ApprovalDate time,\\n    RejectionDate time,\\n    OwnerUserId number,\\n    Comment text,\\n    Text text,\\n    Title text,\\n    Tags text,\\n    RevisionGUID other\\n)\\n\\nCREATE TABLE ReviewTaskTypes (\\n    Id number,\\n    Name text,\\n    Description text\\n)\\n\\nCREATE TABLE TagSynonyms (\\n    Id number,\\n    SourceTagName text,\\n    TargetTagName text,\\n    CreationDate time,\\n    OwnerUserId number,\\n    AutoRenameCount number,\\n    LastAutoRename time,\\n    Score number,\\n    ApprovedByUserId number,\\n    ApprovalDate time\\n)\\n\\nCREATE TABLE Comments (\\n    Id number,\\n    PostId number,\\n    Score number,\\n    Text text,\\n    CreationDate time,\\n    UserDisplayName text,\\n    UserId number,\\n    ContentLicense text\\n)\\n\\nCREATE TABLE PostLinks (\\n    Id number,\\n    CreationDate time,\\n    PostId number,\\n    RelatedPostId number,\\n    LinkTypeId number\\n)[/INST]SELECT COUNT(Posts.Id) AS Answers, (SELECT MAX(Score) FROM (SELECT percent AS Score FROM Posts AS PU WHERE PostTypeId = 2 AND CommunityOwnedDate IS NULL AND PU.OwnerUserId = '##UserId##' ORDER BY Score LIMIT 50) AS t) AS MedianAnswerScore FROM Posts WHERE PostTypeId = 2 AND CommunityOwnedDate IS NULL AND OwnerUserId = '##UserId##'</s>\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df_list = random.sample(df_list, 20000)\n",
    "sampled_df_list[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ff170-2a15-4fdb-9fb6-fc01b0e20637",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "Doing a train, validation and test split with ratio 6:2:2\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab096e3e-f0c4-4b66-8a4c-722c98564628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|█| 12000/12000 [00:00<00:00, 2581242.53 ex\n",
      "Saving the dataset (1/1 shards): 100%|█| 4000/4000 [00:00<00:00, 1542590.66 exam\n",
      "Saving the dataset (1/1 shards): 100%|█| 4000/4000 [00:00<00:00, 1039287.37 exam\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the list\n",
    "random.shuffle(sampled_df_list)\n",
    "\n",
    "# Calculate split indices\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "\n",
    "train_idx = int(len(sampled_df_list) * train_ratio)\n",
    "val_idx = train_idx + int(len(sampled_df_list) * val_ratio)\n",
    "\n",
    "# Split the data, transform it into huggingface dataset and store it locally\n",
    "train = sampled_df_list[:train_idx]\n",
    "val = sampled_df_list[train_idx:val_idx]\n",
    "test = sampled_df_list[val_idx:]\n",
    "train_dataset = Dataset.from_pandas(pd.DataFrame(train, columns=[\"text\"]))\n",
    "val_dataset = Dataset.from_pandas(pd.DataFrame(val, columns=[\"text\"]))\n",
    "test_dataset = Dataset.from_pandas(pd.DataFrame(test, columns=[\"text\"]))\n",
    "train_dataset.save_to_disk(\"train.hf\")\n",
    "val_dataset.save_to_disk(\"val.hf\")\n",
    "test_dataset.save_to_disk(\"test.hf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8126db3b-3269-488b-8a7e-b1420ed858e2",
   "metadata": {},
   "source": [
    "# Fine-tune (include Quantization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64550d4b-695f-4753-a03b-f68355c23af6",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "Since I work on a mac and the mac chip currently does not support Quantization, I will exclude that part. If u need Quantization, uncomment the part below and uncomment the quantization_config in model loading the next section.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5f0b72c-dfd0-4baf-8fee-e9bb9e8b29fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "# quant_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=compute_dtype,\n",
    "#     bnb_4bit_use_double_quant=False,\n",
    "# )\n",
    "\n",
    "base_model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "new_model = \"Llama-2-7b-chat-hf-text2sql\"\n",
    "token = os.getenv('token')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe919db9-1938-4b60-821f-6dc193780eaa",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "Load model from huggingface\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bbcc0ff-40a7-4c27-ba63-c9fa917935ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model, token = token)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model, \n",
    "                                            #quantization_config=quant_config,\n",
    "                                             token = token)\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c42dc0-417b-4f67-94ee-a6464eaabe41",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "We use lora method to fine-tune our model.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9e172aa-2147-42a0-86d6-7ba2eb87f3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_params = LoraConfig(\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "training_params = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1000,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    #optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    logging_steps=25,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0d9f8aa-77b2-4963-8b5f-48a7575c8354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leo/.pyenv/versions/3.10.13/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "/Users/leo/.pyenv/versions/3.10.13/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:222: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████| 12000/12000 [00:01<00:00, 8490.87 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    peft_config=peft_params,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=None,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_params,\n",
    "    packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3c405f-1300-4bf4-bc80-832b1b80aa1e",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "Now the fine-tuned model is saved locally.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "096d842e-7e19-472a-bc33-bcf6817a0ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Llama-2-7b-chat-hf-text2sql/tokenizer_config.json',\n",
       " 'Llama-2-7b-chat-hf-text2sql/special_tokens_map.json',\n",
       " 'Llama-2-7b-chat-hf-text2sql/tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.save_pretrained(new_model)\n",
    "trainer.tokenizer.save_pretrained(new_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
